import requests
import time
import psycopg2
from bs4 import BeautifulSoup
from urllib.parse import urljoin
print("Scrapper started")
BASE_URL = "https://books.toscrape.com/"

RATING_MAP = {
    "One": 1,
    "Two": 2,
    "Three": 3,
    "Four": 4,
    "Five": 5
}

conn = psycopg2.connect(
    host="localhost",
    database="books_db",
    user="postgres",
    password="YOUR_POSTGRES_PASSWORD"
)
cur = conn.cursor()

start_total = time.time()
total_books = 0
timings = []

def scrape_book(book_url, category):
    global total_books

    t0 = time.time()
    response = requests.get(book_url)
    t1 = time.time()

    soup = BeautifulSoup(response.text, "html.parser")
    t2 = time.time()

    title = soup.find("h1").text.strip()
    price = float(soup.find("p", class_="price_color").text[1:])
    availability = soup.find("p", class_="instock availability").text.strip()
    rating_text = soup.find("p", class_="star-rating")["class"][1]
    rating = RATING_MAP[rating_text]

    image_rel = soup.find("img")["src"]
    image_url = urljoin(BASE_URL, image_rel)

    cur.execute("""
        INSERT INTO books (title, category, price, availability, rating, product_url, image_url)
        VALUES (%s,%s,%s,%s,%s,%s,%s)
        ON CONFLICT (product_url) DO NOTHING
    """, (title, category, price, availability, rating, book_url, image_url))
    conn.commit()

    total_books += 1
    timings.append((t1 - t0) + (t2 - t1))

def scrape_category(category_url, category_name):
    next_page = category_url

    while next_page:
        res = requests.get(next_page)
        soup = BeautifulSoup(res.text, "html.parser")

        books = soup.select("article.product_pod h3 a")

        for book in books:
            book_url = urljoin(BASE_URL, book["href"])
            scrape_book(book_url, category_name)

        next_btn = soup.select_one("li.next a")
        if next_btn:
            next_page = urljoin(next_page, next_btn["href"])
        else:
            next_page = None

def main():
    home = requests.get(BASE_URL)
    soup = BeautifulSoup(home.text, "html.parser")

    categories = soup.select("div.side_categories ul li ul li a")

    for cat in categories:
        name = cat.text.strip()
        link = urljoin(BASE_URL, cat["href"])
        print(f"Scraping category: {name}")
        scrape_category(link, name)

    total_time = time.time() - start_total
    avg_time = sum(timings) / len(timings)

    print("\nSCRAPING REPORT")
    print("Total books scraped:", total_books)
    print("Average time per book:", round(avg_time, 4), "seconds")
    print("Total runtime:", round(total_time, 2), "seconds")

if __name__ == "__main__":
    main()

